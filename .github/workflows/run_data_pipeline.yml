# run the complete pipeline on a single cloud vm
# vm specs are repository vars (including disk image, etc)

name: run_data_pipeline_full

on:
    workflow_dispatch: #allows manual trigger from github browser

jobs:
 
  run-data-pipeline:

    runs-on: ubuntu-latest

    steps:
    
      # Checkout code (needed to access bicep file)
      - name: Checkout repo
        uses: actions/checkout@main
     
      # Log into Azure
      - name: Log into Azure
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      # Create resource group and migrate static ip from staging to data rg
      - name: Create resource group and migrate static ip from STAGING -> DATA
        uses: azure/CLI@v2
        env:
          RESOURCE_GROUP_NAME: ${{ vars.AZURE_DATA_RG }}
          RESOURCE_GROUP_LOCATION: ${{ vars.AZURE_DATA_RG_LOCN }}
          AZURE_STATIC_IP_STAGING_RG: ${{ vars.AZURE_STATIC_IP_STAGING_RG }}
          AZURE_SUBSCRIPTION: ${{ vars.AZURE_SUBSCRIPTION }}
          AZURE_VM_STATIC_IP_RESOURCE_ID: ${{ vars.AZURE_DATA_VM_STATIC_IP_RESOURCE_ID_STAGING }}
              
        with:
          azcliversion: latest
          inlineScript: |
            echo "Creating resource group $RESOURCE_GROUP_NAME "
            az group create --name $RESOURCE_GROUP_NAME --location $RESOURCE_GROUP_LOCATION
            echo "Migrating static ip from STAGING -> DATA"
            az resource move --destination-group $RESOURCE_GROUP_NAME --destination-subscription-id $AZURE_SUBSCRIPTION --ids "$AZURE_VM_STATIC_IP_RESOURCE_ID"
      
      # Deploy VM via Bicep file, passing in parameters from environment vars
      - name: Deploy VM with bicep file
        uses: azure/arm-deploy@v1
        with:
          subscriptionId: ${{ vars.AZURE_SUBSCRIPTION }}
          resourceGroupName: ${{ vars.AZURE_DATA_RG }}
          template: ./infrastructure/azure-deploy/create-vm.bicep
          parameters: osImagePublisher="${{ vars.AZURE_DATA_VM_OS_PUBLISHER }}" osImageOffer="${{ vars.AZURE_DATA_VM_OS_OFFER }}" osImageSku="${{ vars.AZURE_DATA_VM_OS_SKU }}" adminUsername="${{ vars.AZURE_DATA_VM_USERNAME }}" adminPublicKey="${{ secrets.AZURE_VM_SSHPUBKEY }}" vmModel="${{ vars.AZURE_DATA_VM_MODEL }}" osDiskSize="${{ vars.AZURE_DATA_VM_DISK_SIZE_GB }}" osDiskType="${{ vars.AZURE_DATA_VM_DISK_TYPE }}" projectName="${{ vars.AZURE_DATA_VM_PROJECT_NAME }}" ipConfig="${{ vars.AZURE_DATA_VM_IPCONFIG }}"
          failOnStdErr: false

      # Bind static ip to NIC
      - name: Associate the static IP with the VM's NIC
        uses: azure/CLI@v2
        env:
          RESOURCE_GROUP_NAME: ${{ vars.AZURE_DATA_RG }} 
          VM_NIC: "${{ vars.AZURE_DATA_VM_PROJECT_NAME }}-nic"
          VM_IPCONFIG: ${{ vars.AZURE_DATA_VM_IPCONFIG }} # this is the default ipconfig name Azure gives the nic which is "myIPconfig"
          VM_STATIC_IP: ${{ vars.AZURE_DATA_VM_STATIC_IP }}  #this is the literal IP address resource name in Azure portal (it need not be a secret handle)
      
        with:
          azcliversion: latest
          inlineScript: |
            az network nic ip-config update --name $VM_IPCONFIG --nic-name $VM_NIC --resource-group $RESOURCE_GROUP_NAME --public-ip-address $VM_STATIC_IP
            
      # Setup github and clone repo to new vm (server). Checkout feature branch.
      - name: ssh to server, setup github keys and clone repo
        uses: appleboy/ssh-action@master
        env:
            GITHUB_PRIVATE_KEY: ${{ secrets.GHUB_PRIVATE_KEY }}
            GITHUB_PUBLIC_KEY: ${{ secrets.GHUB_PUBLIC_KEY }}
            GITHUB_BRANCH_NAME: ${{ github.ref_name }}  
        with:
          host: ${{ vars.AZURE_DATA_VM_SSHHOST }}
          username: ${{ vars.AZURE_DATA_VM_USERNAME }}
          key: ${{ secrets.AZURE_VM_SSHPRIVKEY }}
          port: ${{ vars.AZURE_DATA_VM_SSH_PORT }}
          envs: GITHUB_PRIVATE_KEY, GITHUB_PUBLIC_KEY, GITHUB_BRANCH_NAME
          script: |
            echo "$GITHUB_PRIVATE_KEY" > ~/.ssh/github
            echo "$GITHUB_PUBLIC_KEY" > ~/.ssh/github.pub
            chmod 600 ~/.ssh/github
            eval "$(ssh-agent -s)"
            ssh-add ~/.ssh/github
            ssh-keyscan github.com >> ~/.ssh/known_hosts
            ssh -T git@github.com
            cd ~
            git clone git@github.com:danny-baker/atlas.git
            cd atlas
            
      # Add Azure storage credentials to local .env file
      - name: ssh to server and build .env file (Azure Blob Storage access)
        uses: appleboy/ssh-action@master
        env:
            AZURE_STORAGE_ACCOUNT_NAME: ${{ vars.AZURE_STORAGE_ACCOUNT_NAME }}
            AZURE_STORAGE_ACCOUNT_CONTAINER_NAME: ${{ vars.AZURE_STORAGE_ACCOUNT_CONTAINER_NAME }}
            AZURE_STORAGE_ACCOUNT_KEY: ${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }}

        with:
          host: ${{ vars.AZURE_DATA_VM_SSHHOST }}
          username: ${{ vars.AZURE_DATA_VM_USERNAME }}
          key: ${{ secrets.AZURE_VM_SSHPRIVKEY }}
          port: ${{ vars.AZURE_DATA_VM_SSH_PORT }}
          envs: AZURE_STORAGE_ACCOUNT_NAME, AZURE_STORAGE_ACCOUNT_CONTAINER_NAME, AZURE_STORAGE_ACCOUNT_KEY 
          script: |
            touch ~/atlas/.env
            echo "AZURE_STORAGE_ACCOUNT_NAME=$AZURE_STORAGE_ACCOUNT_NAME" >> ~/atlas/.env
            echo "AZURE_STORAGE_ACCOUNT_CONTAINER_NAME=$AZURE_STORAGE_ACCOUNT_CONTAINER_NAME" >> ~/atlas/.env
            echo "AZURE_STORAGE_ACCOUNT_KEY=$AZURE_STORAGE_ACCOUNT_KEY" >> ~/atlas/.env
            
      # Configure vm (install pip, requrements etc)
      - name: configure vm (install pip, update pip, setup venv, install requirements.txt)
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AZURE_DATA_VM_SSHHOST }}
          username: ${{ vars.AZURE_DATA_VM_USERNAME }}
          key: ${{ secrets.AZURE_VM_SSHPRIVKEY }}
          port: ${{ vars.AZURE_DATA_VM_SSH_PORT }}
          script: |
            sudo apt update
            sudo apt install -y python3-pip
            sudo apt install -y python3.12-venv
            python3 -m venv venv
            source venv/bin/activate
            pip3 install --upgrade pip
            cd ~/atlas
            pip3 install -r requirements.txt

      # Run pipeline task: staging
      - name: pipeline process staging
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AZURE_DATA_VM_SSHHOST }}
          username: ${{ vars.AZURE_DATA_VM_USERNAME }}
          key: ${{ secrets.AZURE_VM_SSHPRIVKEY }}
          port: ${{ vars.AZURE_DATA_VM_SSH_PORT }}
          command_timeout: 200m
          script: |
            source venv/bin/activate
            cd ~/atlas/data
            python3 process_staging.py
            
      # Run pipeline tasks: copper
      - name: pipeline process copper
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AZURE_DATA_VM_SSHHOST }}
          username: ${{ vars.AZURE_DATA_VM_USERNAME }}
          key: ${{ secrets.AZURE_VM_SSHPRIVKEY }}
          port: ${{ vars.AZURE_DATA_VM_SSH_PORT }}
          command_timeout: 200m
          script: |
            source venv/bin/activate
            cd ~/atlas/data
            python3 process_copper.py
            
      # Run pipeline tasks: iron
      # fails with 8GB ram machine. Could try 16GB or 32GB. Noting my lappy has 32.
      - name: pipeline process iron (SMELT)
        uses: appleboy/ssh-action@master
        with:
          host: ${{ vars.AZURE_DATA_VM_SSHHOST }}
          username: ${{ vars.AZURE_DATA_VM_USERNAME }}
          key: ${{ secrets.AZURE_VM_SSHPRIVKEY }}
          port: ${{ vars.AZURE_DATA_VM_SSH_PORT }}
          command_timeout: 200m
          script: |
            source venv/bin/activate
            cd ~/atlas/data
            python3 process_iron.py 